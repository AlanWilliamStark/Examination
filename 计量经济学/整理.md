# 	1 Sample, Sample characteristics (mean, variance, standard deviation, mode median, quantile).

样本、样本特征（均值、方差、标准差、众数中位数、分位数）。

**Sample:** a sample is a set of individuals or objects collected or selected from a statistical population by a defined procedure.

**Sample characteristics:**

**mean:** For a [data set](https://en.wikipedia.org/wiki/Data_set), the *[arithmetic mean](https://en.wikipedia.org/wiki/Arithmetic_mean)*, also known as arithmetic average, is a central value of a finite set of numbers: specifically, the sum of the values divided by the number of values.

**variance:** variance is the [expectation](https://en.wikipedia.org/wiki/Expected_value) of the squared [deviation](https://en.wikipedia.org/wiki/Deviation_(statistics)) of a [random variable](https://en.wikipedia.org/wiki/Random_variable) from its [population mean](https://en.wikipedia.org/wiki/Population_mean) or [sample mean](https://en.wikipedia.org/wiki/Sample_mean). Variance is a measure of [dispersion](https://en.wikipedia.org/wiki/Statistical_dispersion), meaning it is a measure of how far a set of numbers is spread out from their average value.

**standard deviation:** the standard deviation is a measure of the amount of variation or [dispersion](https://en.wikipedia.org/wiki/Statistical_dispersion) of a set of values.

**mode:** The **mode** is the value that appears most often in a set of data values.

**median:** the **median** is the value separating the higher half from the lower half of a data sample. For a [data set](https://en.wikipedia.org/wiki/Data_set), it may be thought of as "the middle" value.

**quantile:** **uantiles** are cut points dividing the [range](https://en.wikipedia.org/wiki/Range_(statistics)) of a [probability distribution](https://en.wikipedia.org/wiki/Probability_distribution) into continuous intervals with equal probabilities, or dividing the [observations](https://en.wikipedia.org/wiki/Observation_(statistics)) in a [sample](https://en.wikipedia.org/wiki/Sample_(statistics)) in the same way. There is one fewer quantile than the number of groups created. **分位数**是将[概率分布](https://en.wikipedia.org/wiki/Probability_distribution)[的范围](https://en.wikipedia.org/wiki/Range_(statistics))划分为具有相等概率的连续区间的切点，或者以相同的方式将[样本](https://en.wikipedia.org/wiki/Sample_(statistics))中的除以[观测值](https://en.wikipedia.org/wiki/Observation_(statistics))。分位数比创建的组数少一个。









# 2  Histogram, Empirical Cumulative distribution function

直方图、经验累积分布函数



# 3 Criteria for testing goodness of fit of distribution models: Kolmogorov, Pearson (chi-square), 



# 4 Uniformity criteria for two or more samples (Kolmogorov Smirnov test, Mann–Whitney test,  Wilcoxon Test). 



# 5 Parametric hypotheses for two samples. Equality criteria for mean and variances (Student test,  Fisher test). 



# 6 Parametric hypotheses for one sample. Criteria about the value of distribution parameters. 

一个样本的参数假设。关于分布参数值的判定。

置信区间：在区间估计中，由样本统计量构造的总体参数的估计区间

![img](%E6%95%B4%E7%90%86.assets/clip_image002.jpg)

 

一个样本的参数假设：

parametric hypothesis test ：简称假设检验，是数理统计学中根据一定假设条件由样本推断总体的一种方法。其基本原理是先对总体的特征作出某种假设，然后通过抽样研究的统计推理，对此假设应该被拒绝还是接受作出推断。

 

具体作法是：根据问题的需要对所研究的总体作某种假设，记作H0；选取合适的统计量，这个统计量的选取要使得在假设H0成立时，其分布为已知；

由实测的样本，计算出统计量的值，并根据预先给定的显著性水平进行检验，作出拒绝或接受假设H0的判断。

常用的假设检验方法有u—检验法、t检验法、χ2检验法(卡方检验)、F—检验法等。

 

参数假设检验又称统计假设检验，是一种基本的统计推断形式，也是数理统计学的一个重要的分支，用来判断样本与样本，样本与总体的差异是由抽样误差引起还是本质差别造成的统计推断方法。其基本原理是先对总体的特征作出某种假设，然后通过抽样研究的统计推理，对此假设应该被拒绝还是接受作出推断。

 

假设是否正确，要用从总体中抽出的样本进行检验，与此有关的理论和方法，构成假设检验的内容。设A是关于总体分布的一项命题，所有使命题A成立的总体分布构成一个集合H0，称为原假设(常简称假设)。使命题A不成立的所有总体分布构成另一个集合H1，称为备择假设。如果H0可以通过有限个实参数来描述，则称为参数假设，否则称为非参数假设(见非参数统计)。如果H0(或H1)只包含一个分布，则称原假设(或备择假设)为简单假设，否则为复合假设。对一个假设H0进行检验，就是要制定一个规则，使得有了样本以后，根据这规则可以决定是接受它（承认命题A正确），还是拒绝它（否认命题A正确）。这样，所有可能的样本所组成的空间（称样本空间）被划分为两部分HA和HR(HA的补集)，当样本x∈HA时，接受假设h0；当x∈HR时，拒绝H0。集合HR常称为检验的拒绝域，HA称为接受域。因此选定一个检验法，也就是选定一个拒绝域，故常把检验法本身与拒绝域HR等同起来。

 

步骤：1、提出检验假设又称无效假设，符号是H0；备择假设的符号是H1。

H0：样本与总体或样本与样本间的差异是由抽样误差引起的；

H1：样本与总体或样本与样本间存在本质差异；

预先设定的检验水准为0.05；当检验假设为真，但被错误地拒绝的概率，记作α，通常取α=0.05或α=0.01。

 

2、选定统计方法，由样本观察值按相应的公式计算出统计量的大小，如X2值、t值等。根据资料的类型和特点，可分别选用Z检验，T检验，秩和检验和卡方检验等。

 

3、根据统计量的大小及其分布确定检验假设成立的可能性P的大小并判断结果。若P>α，结论为按α所取水准不显著，不拒绝H0，即认为差别很可能是由于抽样误差造成的，在统计上不成立；如果P≤α，结论为按所取α水准显著，拒绝H0，接受H1，则认为此差别不大可能仅由抽样误差所致，很可能是实验因素不同造成的，故在统计上成立。P值的大小一般可通过查阅相应的界值表得到。

 

这里的显著性水平指的是当假设正确时被拒绝的概率，即弃真概率，一般取0.01或0.05。当检验统计量的概率p值小于显著性水平时，则认为如果此时拒绝零假设而弃真错误的概率小于显著性水平，即低于预先给定的水平，也就是说犯错误的概率小到我们能容忍的范围，这是可以拒绝零假设；反之，如果检验统计量的概率p值大于显著性水平，如果拒绝零假设，弃真错误的概率大于预先给定的容忍水平，这时不应该拒绝零假设。

 

P < 0.01, 0.05;  拒绝H0；  接受H1。

P > 0.01,0.05;   接受H0，  拒绝H1.

 

 

![img](%E6%95%B4%E7%90%86.assets/clip_image004.png)

```R
#Parametric Hyp.

#H0: a=4.4% H1: a Not =4.4%  under sigma^2 0.5%^2 with significant level 0.05
install.packages('BSDA')
library(BSDA)
z.test(efr, mu=4.4, sigma.x = 0.5, conf.level = 0.95, alternative = "t")
#p-value = 0.009995< 0.05 Ho is rejected, a does not equal 4.4

#H0: a=4.4% H1: a>4.4%  under sigma^2 0.5%^2 with significant level 0.05
z.test(efr, mu=4.4, sigma.x = 0.5, conf.level = 0.95, alternative = "g")
#p-value = 0.995> 0.05 there is no reason to  reject Ho, a not > 4.4

z.test(efr, mu=4.4, sigma.x = 0.5, conf.level = 0.95, alternative = "l")
p-value = 0.004998 <0.05 we reject H0 a<4.4

```

![img](%E6%95%B4%E7%90%86.assets/clip_image008.png)

```R
#H0: a=4.4% H1: a Not =4.4%  under sigma^2 is unknown  with significant level 0.05
t.test(efr,mu=4.4, conf.level = 0.95, alternative = "t")
p-value = 0.04119 <0.05 we reject H0 a not equal 4.4

```

 

 

![img](%E6%95%B4%E7%90%86.assets/clip_image010.png)

```R
install.packages('EnvStats')
library(EnvStats)
varTest(efr, sigma.squared = 0.5, conf.level = 0.95, alternative = "t")
#p-value = 0.3118>0.05   sigma.squared = 0.5

varTest(efr, sigma.squared = 0.2, conf.level = 0.95, alternative = "g")

```

 

![img](%E6%95%B4%E7%90%86.assets/clip_image013.png)

critical area：临界区

```R
#H0: p=1/3 Ha: p not 1/3

efr_1<-subset(efr, efr>3.7)
efr_1
m<-length(efr_1)
m
n<-length(efr)
n
binom.test(m,n,p=1/3, conf.level = 0.95, alternative = "t")
#p-value = 0.0001279<0.05, Ho is rejected so, the part of banks with efr>3.7 is not equal 1/3
binom.test(m,n,p=1/3, conf.level = 0.95, alternative = "l")

binom.test(m,n,p=1/3, conf.level = 0.95, alternative = "g")
#p-value = 8.827e-05 the part of banks, with efr>3.7, > 1/3


prop.test(m,n,p=1/3, conf.level = 0.95, alternative = "t")
#p-value = 0.0001006 <0.05 Ho is rejected so, the part of banks with efr>3.7 is not equal 1/3

```



分布参数（distributed parameter）是统计学的基本概念之一。指统计学中用以区别分布函数族{Fθ|θ∈Θ}中的各个分布的指标θ的函数g(θ)和分布的数字特征，如总体均值、总体标准差、总体相关系数等。参数的所有可能值组成的集合Θ称为参数空间。参数一般不易获得，可根据反映总体情况的样本求出的统计量去估计它。

 

使用 p 值评估分布的拟合。

将每个分布或变换的 p 值与显著性水平进行比较。通常，显著性水平（用 α 或 alpha 表示）为 0.05 即可。显著性水平 0.05 指示当数据实际上服从分布时，判定数据不服从分布的风险为 5%。

P ≤ α：数据不服从分布（否定 H0）

如果 p 值小于或等于显著性水平，则否定原假设并得出数据不服从分布的结论。

P > α：无法得出数据不服从分布的结论（无法否定 H0）

如果 p 值大于显著性水平，则无法否定原假设。证据不足，无法得出数据不服从分布的结论。您可以假设数据服从分布。

 

 

# 7 Non-Parametric Hypotheses. Median test. 

Non-Parametric Hypotheses：在总体方差未知或知道甚少的情况下，利用样本数据对总体分布形态等进行推断的方法。

![img](%E6%95%B4%E7%90%86.assets/clip_image002.png)

单样本：K-S检验方法能够利用样本数据推断样本来自的总体是否服从某一理论分布，是一种拟合优度的检验方法，适用于探索连续型随机变量的分布。

单样本K-S检验的原假设是：样本来自的总体与指定的理论分布无显著差异，SPSS的理论分布主要包括正态分布、均匀分布、指数分布和泊松分布等。

 

 

两独立样本：K-S检验不仅能够检验单个总体是否服从某一理论分布，还能够检验两总体分布是否存在显著差异。其原假设是：两组独立样本来自的两总体的分布无显著差异。

![文本框: #NonParametric Hypothises install.packages('twosamples') library(twosamples) ks_test(CM,UM) ](%E6%95%B4%E7%90%86.assets/clip_image003.png)这里是以变量值的秩作为分析对象，而非变量值本身。

 

 

Mann-Whitney检验是独立样本t检验的非参数版本。该检验主要处理包含等级数据的两个独立样本，SPSSAU中称为非参数检验。

 

Wilcoxon符号秩检验也是通过分析两配对样本，对样本来自的两总体的分布是否存在差异进行判断。其原假设是：两配对样本来自的两总体的分布无显著差异。

基本思想是：首先，按照符号检验的方法，分布用第二组样本的各个观察值减去第一组对应样本的观察值。差值为正则记为正号，为负则记为负号，并同时保存差值数据；然后，将差值变量按升序排序，并求出差值变量的秩；最后，分布计算正号秩总和W+和负号秩和W-。

 

ad.test: Anderson-Darling test数据值的数字向量，其数量必须大于 7。允许缺失值。通过查看它们之间的平方差的加权和来比较两个 ECDF——在联合样本中的每个点进行评估。权重由该点的联合 ECDF 的方差决定，该方差在联合分布的中间达到峰值

![文本框: vec1  =  rnorm ( 20 )  vec2  =  rnorm ( 20 , 4 )  ad_test ( vec1 , vec2 ) ](%E6%95%B4%E7%90%86.assets/clip_image004-16418256735752.png)

 

Median test ：median test is a special case of Pearson's chi-squared test. It is a nonparametric test that tests the null hypothesis that the medians of the populations from which two or more samples are drawn are identical. The data in each sample are assigned to two groups, one consisting of data whose values are higher than the median value in the two groups combined, and the other consisting of data whose values are at the median or below. A Pearson's chi-squared test is then used to determine whether the observed frequencies in each sample differ from expected frequencies derived from a distribution combining the two groups. 

 

确定两个或多个组的中位数是否存在差异。

计算两个总体中位数之间的差值的范围。

 

样本数据不必是正态分布的

各个组的分布应当具有相同的分布形状和散布，而且包括异常值。

如果组的分布不包括异常值，请使用Kruskal-Wallis 检验，因为它的功效更大。

如果组的分布服从正态分布，请考虑使用单因子方差，因为它的功效更大。

```R
#Kruskal Wallis test
#HO: May price of fuel  has the same distribution in each FedDistrict
kruskal.test(JetFuelPrices$May,JetFuelPrices$FedDistrict)
#p-value = 2.378e-05<0.05 we reject Ho 
boxplot(May~FedDistrict, data=JetFuelPrices)
kruskal.test(JetFuelPrices$June,JetFuelPrices$FedDistrict)
#p-value = 3.255e-06<0.05 we reject Ho 

boxplot(June~FedDistrict, data=JetFuelPrices)

J3<-subset(JetFuelPrices, JetFuelPrices$FedDistrict=="Central"|JetFuelPrices$FedDistrict=="Ural"|JetFuelPrices$FedDistrict=="Privol" )
View(J3)
kruskal.test(J3$June,J3$FedDistrict)
#p-value = 0.1481 >0.05 there is no reason to reject Ho we can say June prices of fuel have the same distribution
boxplot(June~FedDistrict, data=J3) 

```

The sign test is a statistical method to test for consistent differences between pairs of observations, such as the weight of subjects before and after treatment. Given pairs of observations (such as weight pre- and post-treatment) for each subject, the sign test determines if one member of the pair (such as pre-treatment) tends to be greater than (or less than) the other member of the pair (such as post-treatment).

```R
#H0: median =41000 (in June) Ha:    median not =41000 
SIGN.test(JetFuelPrices$June, md=41000, alternative = "t", conf.level = 0.95 )
#p-value = 0.01144 <0.05  median not =41000 

# Compare medians of prices in June and July
#Ho: med1=med2   Ha: med1 NOT =med2

SIGN.test(JetFuelPrices$June, JetFuelPrices$July, m=0, alternative = "t", conf.level = 0.95)
#p-value = 0.07224> 0.05 Ho: med1=med2 

SIGN.test(JetFuelPrices$May, JetFuelPrices$July, m=0, alternative = "t", conf.level = 0.95)
#p-value = 0.003183< 0.05 medians are different

SIGN.test(JetFuelPrices$June, JetFuelPrices$July, m=0, alternative = "t", conf.level = 0.95)
p-value = 1  #Ho: med1-med2=1000 

median(JetFuelPrices$May, na.rm = TRUE) -median(JetFuelPrices$July)
median(JetFuelPrices$June) -median(JetFuelPrices$July)

#Ho: med1=med2=med3=...  Ha: at least one is different
install.packages("agricolae")
library(agricolae)

Median.test(JetFuelPrices$June,JetFuelPrices$FedDistrict) 
P.Value 8.087849e-05<0.05 Ha: at least one is different

```



# 8 Basic assumptions of linear regression analysis. Normal (Gaussian) distribution. 

线性回归分析的基本假设。正态(高斯)分布。



 

线性回归分析的基本假设：

Ø 回归分析模型是正确设定的。

Ø 自变量x服从正态分布。

Ø 在给定自变量x的情况下，随机误差项μ的均值为0，μ与x同方差，μ与x不序列相关。

Ø 因变量x在所抽样本中具有变异性，而且随着样本量的增加，因变量x的方差趋近于一个非零常数。

Ø 随机误差项μ服从零均值、同方差的正态分布。

 

正态(高斯)分布：是一个非常常见的连续概率分布。则其[概率密度函数](https://zh.wikipedia.org/wiki/機率密度函數)为

![img](%E6%95%B4%E7%90%86.assets/clip_image002-16418256501411.jpg)

正态分布的数学期望值或期望值 μ等于位置参数，决定了分布的位置；其方差σ2的开平方或标准差σ等于尺度参数，决定了分布的幅度。正态分布的概率密度函数曲线呈钟形，因此人们又经常称之为钟形曲线我们通常所说的标准正态分布是位置参数μ=0，尺度参数σ2= 1的正态分布。

![img](%E6%95%B4%E7%90%86.assets/clip_image004.jpg)

密度函数关于平均值对称

Ø 平均值与它的众数（statistical mode）以及中位数（median）同一数值。

Ø 函数曲线下68.268949%的面积在平均数左右的一个标准差范围内。

Ø 95.449974%的面积在平均数左右两个标准差2σ的范围内。

Ø 99.730020%的面积在平均数左右三个标准差3σ的范围内。

Ø 99.993666%的面积在平均数左右四个标准差4σ的范围内。

函数曲线的拐点（inflection point）为离平均数一个标准差距离的位置。

# 9 Verification of homoskedasticity using the Goldfeld-Quandt method. 



# 10 Properties of estimates of the method of least squares of linear regression coefficients. Dispersion  matrix of estimates. 



# 11 Student distribution. Testing hypotheses about the values of linear regression coefficients.  Checking the statistical significance of coefficient estimates. Confidence intervals for linear  regression coefficients. 



# 12 Fisher distribution. Coefficient of determination. Testing the hypothesis of the statistical  significance of multiple linear regression as a whole. 

费希尔分布。 确定系数。 检验多元线性回归作为一个整体的统计显着性假设。

## F-distribution



## **Coefficient of determination**

**Not to be confused with Coefficient of variation or  Coefficient of correlation**

![image-20220109164009153](%E6%95%B4%E7%90%86.assets/image-20220109164009153.png)

![image-20220109164020246](%E6%95%B4%E7%90%86.assets/image-20220109164020246.png)





# 13 Point forecast. Confidence intervals for forecasting individual values. 

点预测。 预测单个值的置信区间。

**Point forecast** refers to a [forecast](https://ec.europa.eu/eurostat/statistics-explained/index.php?title=Glossary:Forecasting) of the value of a random variable y *t at horizon h*, conditional on the information set in [reference period](https://ec.europa.eu/eurostat/statistics-explained/index.php?title=Glossary:Reference_period) *T*.

# 14 Nonlinear paired regression. Classification of nonlinaear dependencies. Methods for evaluating  parameters. 

非线性配对回归。 非线性依赖的分类。 评估参数的方法。

**Nonlinear regression **is an extension of linear regression, where linear means that the expoonent of each variable is 1, while nonlinear means that at least one variable has an exponent other than 1

**Converting nonlinear regression to linear regression: (linearization)** 

Many nonlinear regressions can be transformed into linear regressions by means of variable substitution. Common transformation models are:

![image-20220110173541157](%E6%95%B4%E7%90%86.assets/image-20220110173541157.png)

​	



# 15 Private correlation coefficient. Multiple correlation coefficient. 



# 16 Formal statistical methods for checking the adequacy of the selected model with the available  statistical data. 



# 17 Correction of statistical conclusions in the presence of heteroskedasticity, in the presence of autocorrelation of errors, in the presence of seasonality. Multicollinearity, dummy variables. 

（对存在异方差，存在误差自相关的情况下的统计结论进行校正。多重共线性关系，虚拟

变量。）

Multiple collinearity is an accurate or approximately accurate linear relationship between the individual explanatory variables.多重共线性是指各个解释变量之间有准确或近似准确的线性关系。

# 18 Classification analysis. The key features of Classification（分类分析，分类的主要特征）

![img](%E6%95%B4%E7%90%86.assets/clip_image002-16418258728083.jpg)

![img](%E6%95%B4%E7%90%86.assets/clip_image004-16418258728094.jpg)

![img](%E6%95%B4%E7%90%86.assets/clip_image006.jpg)

![img](%E6%95%B4%E7%90%86.assets/clip_image008.jpg)

 

# 19 What is the input and output (have label)（输入和输出（有标签））

![img](%E6%95%B4%E7%90%86.assets/clip_image010.jpg)

**Input:**Develop a set of training data which contains a certain set of attributes as well as the likely outcome. And then input the data.

**Ouput:**Discover how that set of attributes reaches its conclusion. And then output the result.

 

# 20 Describe the decision tree process.（描述决策树过程）

![img](%E6%95%B4%E7%90%86.assets/clip_image012.jpg)

# 21 What are the formulas included in the decision tree task (Entropy)（决策树任务（熵）中包含的公式是什么） 

![img](%E6%95%B4%E7%90%86.assets/clip_image014.jpg)

# 22 Clustering analysis.The key features of Clustering（聚类分析。集群化的关键特性）

![img](%E6%95%B4%E7%90%86.assets/clip_image016.jpg)

# 23 What is the input and output? （它的输入和输出是什么？）

**Input:**Step 1: Confirm data is metric.Step 2: Scale the data.Step 3: Select Segmentation Variables.Step 4: Define similarity measure.Step 5: Visualize Pair-wise Distances.Step 6: Method and Number of Segments. Step 7: Input.

**Output:** Step 1: Profile and interpret the segments. Step 2: Robustness Analysis. Step 3: Output.

 

 

 

 

 

 

# 24 Describe the K-mean process. What are the formulas included in the K-mean task (Distance function)（描述k均值过程。K平均任务（距离函数）中包含的公式是什么）

![img](%E6%95%B4%E7%90%86.assets/clip_image018.jpg)

![img](%E6%95%B4%E7%90%86.assets/clip_image020.jpg)

给定k，k-means算法分四个步骤实现：

1将对象划分为k个非空的子集

2将种子点计算为当前分区的集群的质心（质心是集群的中心，即平均点）

3将每个对象分配给具有最近的种子点的集群

4回到步骤2，当没有新的任务时停止
